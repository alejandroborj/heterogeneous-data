{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "\n",
    "import dataset\n",
    "import data_reader\n",
    "import plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU : cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Choosing device for tensor processing\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using GPU :\", device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NAME = \"25ep_earlystp_ft\"\n",
    "EXP_NAME = \"25ep\"\n",
    "\n",
    "DATA_SET_NAME = f\"data_set_x20_100%_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wsi_class(wsi_data_set):\n",
    "    global net\n",
    "    \"\"\"\n",
    "    Input: \n",
    "    - wsi_data_set, patches from a given WSI, dataset object\n",
    "    - y, patch labels\n",
    "    Outputs:\n",
    "    - output, Prediction\n",
    "    \"\"\"\n",
    "    wsi_dataloader = DataLoader(wsi_data_set, batch_size=64)\n",
    "    outputs = []\n",
    "    loss = 0\n",
    "\n",
    "    for batch_X, batch_y in iter(wsi_dataloader):\n",
    "        batch_X, batch_y = batch_X.type(torch.FloatTensor).to(device).permute(0, 3, 2, 1), batch_y.type(torch.FloatTensor).to(device) \n",
    "\n",
    "        mean = [0.485, 0.456, 0.406]\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "        normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "        for i, x in enumerate(batch_X):\n",
    "            batch_X[i] = normalize(batch_X[i]/255) # Np array\n",
    "        \n",
    "        output = net(batch_X)\n",
    "        outputs.extend(output.cpu())\n",
    "        #print(batch_y.size(), output.size())\n",
    "        loss += nn.CrossEntropyLoss()(output, batch_y).cpu()\n",
    "\n",
    "    y_pred = [torch.argmax(i) for i in outputs] # 1 means positive diagnosis: (1,0) => 1\n",
    "    prob_neg = y_pred.count(0)/len(y_pred)\n",
    "    prob_coad = y_pred.count(1)/len(y_pred)\n",
    "    prob_read = y_pred.count(2)/len(y_pred)\n",
    "\n",
    "    output = [prob_neg, prob_coad, prob_read]\n",
    "    loss = loss/len(wsi_data_set)\n",
    "\n",
    "    return output, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read lmdb\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71d099a4f3d4063ace4918d189d6c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:146: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:178.)\n",
      "  return default_collate([torch.as_tensor(b) for b in batch])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss:  0.012548898\n",
      "Acc:  0.68\n",
      "f1:  0.6571969696969697\n",
      "CONF: \n",
      " [[10  0  0]\n",
      " [ 2 36 10]\n",
      " [ 0 12  5]] \n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`data` and `annot` must have same shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alejandro\\Desktop\\heterogeneous-data\\src\\WSI\\pred_WSI.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/src/WSI/pred_WSI.ipynb#ch0000004?line=43'>44</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mf1: \u001b[39m\u001b[39m\"\u001b[39m, f1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/src/WSI/pred_WSI.ipynb#ch0000004?line=44'>45</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCONF: \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m, conf_m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/src/WSI/pred_WSI.ipynb#ch0000004?line=46'>47</a>\u001b[0m plots\u001b[39m.\u001b[39;49mplot_conf(SPLIT_NAME, conf_m)\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\Desktop\\heterogeneous-data\\src\\WSI\\plots.py:139\u001b[0m, in \u001b[0;36mplot_conf\u001b[1;34m(SPLIT_NAME, conf)\u001b[0m\n\u001b[0;32m    136\u001b[0m labels \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mv1\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mv2\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mv3\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m v1, v2, v3 \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(group_names,group_counts,group_percentages)]\n\u001b[0;32m    137\u001b[0m labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(labels)\u001b[39m.\u001b[39mreshape(\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m)\n\u001b[1;32m--> 139\u001b[0m sn\u001b[39m.\u001b[39;49mheatmap(conf, annot\u001b[39m=\u001b[39;49mlabels, fmt\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, cmap\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mBlues\u001b[39;49m\u001b[39m'\u001b[39;49m, ax\u001b[39m=\u001b[39;49m ax)\n\u001b[0;32m    141\u001b[0m ax\u001b[39m.\u001b[39mset_xticklabels(lab)\n\u001b[0;32m    142\u001b[0m ax\u001b[39m.\u001b[39mset_yticklabels(lab)\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\seaborn\\_decorators.py:46\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m     37\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPass the following variable\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m as \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39mkeyword arg\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFrom version 0.12, the only valid positional argument \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     )\n\u001b[0;32m     45\u001b[0m kwargs\u001b[39m.\u001b[39mupdate({k: arg \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args)})\n\u001b[1;32m---> 46\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\seaborn\\matrix.py:540\u001b[0m, in \u001b[0;36mheatmap\u001b[1;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39m\"\"\"Plot rectangular data as a color-encoded matrix.\u001b[39;00m\n\u001b[0;32m    363\u001b[0m \n\u001b[0;32m    364\u001b[0m \u001b[39mThis is an Axes-level function and will draw the heatmap into the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[39m    ...     ax = sns.heatmap(corr, mask=mask, vmax=.3, square=True)\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[39m# Initialize the plotter object\u001b[39;00m\n\u001b[1;32m--> 540\u001b[0m plotter \u001b[39m=\u001b[39m _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0;32m    541\u001b[0m                       annot_kws, cbar, cbar_kws, xticklabels,\n\u001b[0;32m    542\u001b[0m                       yticklabels, mask)\n\u001b[0;32m    544\u001b[0m \u001b[39m# Add the pcolormesh kwargs here\u001b[39;00m\n\u001b[0;32m    545\u001b[0m kwargs[\u001b[39m\"\u001b[39m\u001b[39mlinewidths\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m linewidths\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\seaborn\\matrix.py:173\u001b[0m, in \u001b[0;36m_HeatMapper.__init__\u001b[1;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[39mif\u001b[39;00m annot_data\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m plot_data\u001b[39m.\u001b[39mshape:\n\u001b[0;32m    172\u001b[0m             err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m`data` and `annot` must have same shape.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 173\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err)\n\u001b[0;32m    174\u001b[0m     annot \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39m# Save other attributes to the object\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: `data` and `annot` must have same shape."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SPLIT_NAME = DATA_SET_NAME + f\"{1}\"\n",
    "MODEL_NAME = EXP_NAME + f\"{0}\"\n",
    "\n",
    "net = torch.load(f\"C:\\\\Users\\\\Alejandro\\\\Desktop\\\\heterogeneous-data\\\\results\\\\WSI\\\\models\\\\{MODEL_NAME}.pth\") # Model loading\n",
    "\n",
    "X, y, _ , case_ids = data_reader.read_lmdb(f\"D:\\data\\WSI\\COAD\\patches\\{SPLIT_NAME}\")\n",
    "\n",
    "sample_ids = [case_id[2:18] for case_id in case_ids] # Taking only the sample_id, not patch id\n",
    "\n",
    "outputs, loss, labels = [], [], []\n",
    "unique_sample_ids = np.unique(sample_ids)\n",
    "sample_ids = np.array(sample_ids)\n",
    "\n",
    "for unique_sample_id in tqdm(unique_sample_ids):\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        ii = np.where(sample_ids == unique_sample_id)[0]\n",
    "\n",
    "        wsi_data_set = dataset.PatchDataset([], [], [])\n",
    "\n",
    "        wsi_data_set.inputs.extend(X[ii[0]:ii[-1]])# Taking the patches from a given wsi\n",
    "        wsi_data_set.labels.extend(y[ii[0]:ii[-1]])\n",
    "        wsi_data_set.case_ids.extend(sample_ids)\n",
    "        \n",
    "        output = wsi_class(wsi_data_set)\n",
    "        outputs.append(output[0])\n",
    "        loss.append(output[1])\n",
    "        labels.append(np.argmax(y[ii[0]])) # OHE to binary\n",
    "\n",
    "        del wsi_data_set\n",
    "\n",
    "loss = np.mean(loss)\n",
    "\n",
    "out = [np.argmax(output) for output in outputs]\n",
    "\n",
    "conf_m = sklearn.metrics.confusion_matrix(labels, out, labels=[0, 1, 2])\n",
    "acc = sklearn.metrics.accuracy_score(labels, out)\n",
    "f1 = sklearn.metrics.f1_score(labels, out, average= \"macro\")\n",
    "auc = 0 #sklearn.metrics.roc_auc_score(y_true, y_pred, average= \"micro\", multi_class=\"ovr\") #!!!!\n",
    "\n",
    "print(\"Mean Loss: \", loss)\n",
    "print(\"Acc: \", acc)\n",
    "print(\"f1: \", f1)\n",
    "print(\"CONF: \\n\", conf_m, \"\\n\")\n",
    "\n",
    "plots.plot_conf(SPLIT_NAME, conf_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc = []\n",
    "\n",
    "# ROC\n",
    "for i in reversed(np.linspace(0,1,10000)):\n",
    "    out = [1 if output>i else 0 for output in outputs]\n",
    "    conf_m = confusion_matrix(labels, out, labels=[0, 1])\n",
    "    roc.append(conf_m[1][1]/(conf_m[1][0]+conf_m[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_roc(SPLIT_NAME, roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing only the images from the according splits (10CV)\n",
    "\n",
    "SPLITS = 1 # Number of iterations > n_splits\n",
    "\n",
    "for SPLIT in range(SPLITS):\n",
    "    MODEL_NAME = EXP_NAME + f\"{SPLIT}\"\n",
    "    SPLIT_NAME = DATA_SET_NAME + f\"{SPLIT}\"\n",
    "\n",
    "    test_set = dataset.PatchDataset([], [], [])\n",
    "\n",
    "    X_, y_, _ , case_ids_ = data_reader.read_lmdb(f\"C:/Users/Alejandro/Desktop/heterogeneous-data/data/WSI/patches/{SPLIT_NAME}\")\n",
    "\n",
    "    test_set.inputs.extend(X_)\n",
    "    test_set.labels.extend(y_)\n",
    "    test_set.case_ids.extend(case_ids_)\n",
    "\n",
    "    print(f\"Loading model {MODEL_NAME}\\n\")\n",
    "\n",
    "    net = torch.load(f\"C:\\\\Users\\\\Alejandro\\\\Desktop\\\\heterogeneous-data\\\\results\\\\WSI\\\\models\\\\{MODEL_NAME}.pth\") # Model loading\n",
    "\n",
    "    test_wsi()\n",
    "\n",
    "    del test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de74446a7cd3a56c425ecbffb2a7ad915342ddab3c48353acb4566475bd7705f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('openslide')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
