{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "import time\n",
    "\n",
    "import data_reader\n",
    "import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU : cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Choosing device for tensor processing\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"Using GPU :\", device)\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and data variables\n",
    "\n",
    "MODE = \"w\"\n",
    "EXP_NAME = \"25ep_earlystp_ft\"\n",
    "\n",
    "DATA_SET_NAME = f\"data_set_x20_100%_split\"\n",
    "PATCH_SIZE = 512\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 25\n",
    "\n",
    "SIZE_X = PATCH_SIZE\n",
    "SIZE_Y = PATCH_SIZE\n",
    "\n",
    "threshold = 0.05 # Loss difference for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m): # XAVIER initialization for final layer weight initialization\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def init():\n",
    "    global net, loss_function, scheduler, optimizer, MODEL_NAME\n",
    "\n",
    "    net = torchvision.models.resnet18(pretrained=True).to(device)\n",
    "    \n",
    "    for param in net.parameters():\n",
    "        param.requires_grad = False # Freezing the convolutional layers\n",
    "\n",
    "    for param in net.layer4[1].parameters():\n",
    "        param.requires_grad = True # Unfreezing the last residual block\n",
    "    \n",
    "    \n",
    "    net.fc = nn.Sequential(\n",
    "                nn.Linear(512, 2),\n",
    "                #nn.ReLU(inplace=True),\n",
    "                #nn.Linear(128, 2),\n",
    "                nn.Softmax(dim = -1)\n",
    "                ).to(device)\n",
    "\n",
    "    net.fc.apply(init_weights) # Xavier init\n",
    "\n",
    "    #print(f\"Loading {MODEL_NAME}\")\n",
    "    net = torch.load(f\"C:\\\\Users\\\\Alejandro\\\\Desktop\\\\heterogeneous-data\\\\results\\\\WSI\\\\models\\\\{MODEL_NAME}.pth\") # Model loading\n",
    "\n",
    "    n_params = sum(p.numel() for p in net.fc.parameters())# + sum(p.numel() for p in net.layer4[1].parameters())\n",
    "    print(\"Number of free parameters: \", n_params)\n",
    "\n",
    "    #Hyperparameters:\n",
    "    learning_rate = 1E-5 # LR\n",
    "    loss_function = nn.BCELoss()  # Loss # [1,0] es positivo y [0,1] negativo\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08)# Optimizer\n",
    "    lambda1 = lambda epoch: 1 ** epoch # Scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fwd_pass(X, y, train=False):\n",
    "# IMPORTANTE, TRAIN = FALSE PARA QUE NO ENTRENE CON EL TEST DATA ESTO ES PARA PODER HACER TEST MIENTRAS ENTRENO Y VALIDO, \n",
    "# SE ESPERA QUE LA EXACTITUD EN EL TEST DE VALIDACIÃ“N SEA MENOR\n",
    "    if train: \n",
    "        net.zero_grad()\n",
    "        \n",
    "    # NORMALIZATION\n",
    "    mean = [0.485, 0.456, 0.406]\n",
    "    std = [0.229, 0.224, 0.225]\n",
    "    normalize = torchvision.transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "    for i, x in enumerate(X):\n",
    "        X[i] = normalize(X[i]/255) # Np array\n",
    "\n",
    "    outputs = net(X)\n",
    "    matches = [torch.argmax(i) == torch.argmax(j) for i,j in zip(outputs, y)]\n",
    "    y_pred = [torch.argmin(i) for i in outputs.cpu()] # 1 means positive diagnosis: (1,0) => 1\n",
    "    y_true = [torch.argmin(i) for i in y.cpu()]\n",
    "\n",
    "    acc = matches.count(True)/len(matches)\n",
    "    loss = loss_function(outputs, y)\n",
    "    conf_m = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
    "    \n",
    "    if train:\n",
    "        loss.backward() # Calculate gradients using backprop\n",
    "        optimizer.step() # Updates W and b using previously calculated gradients\n",
    "\n",
    "    return acc, loss, conf_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "  global net, loss_function, scheduler, threshold, optimizer, train_set, val_set, MODEL_NAME, EPOCHS\n",
    "  \n",
    "  print(MODEL_NAME)\n",
    "  patience = 0\n",
    "\n",
    "  with open(f\"C:\\\\Users\\\\Alejandro\\\\Desktop\\\\heterogeneous-data\\\\results\\\\WSI\\\\log\\\\model_{MODEL_NAME}.log\", MODE) as f:\n",
    "    for epoch in range(EPOCHS):\n",
    "      acc, loss = 0, 0,\n",
    "      val_acc, val_loss = 0, 0,\n",
    "      conf_m, val_conf_m = np.array([[0,0],[0,0]]), np.array([[0,0],[0,0]])\n",
    "\n",
    "      print(\"\\nEPOCH: \", epoch+1)\n",
    "\n",
    "      for batch_X, batch_y in tqdm(iter(train_dataloader)):\n",
    "\n",
    "        batch_X, batch_y = batch_X.type(torch.FloatTensor).to(device).permute(0, 3, 2, 1), batch_y.type(torch.FloatTensor).to(device) \n",
    "        \n",
    "        net.train() # Making sure that the model is in training mode\n",
    "        \n",
    "        acc_aux, loss_aux, conf_m_aux = fwd_pass(batch_X, batch_y, train=True)\n",
    "        \n",
    "        acc += acc_aux*(len(batch_X)/len(train_set)) # Calculating the average loss and acc through batches sum ACCi*Wi/N (Wi = weight of the batch)\n",
    "        loss += loss_aux*(len(batch_X)/len(train_set))\n",
    "        conf_m += conf_m_aux\n",
    "\n",
    "        \"\"\"\n",
    "        i += 1\n",
    "    \n",
    "        if i%100 == 0:\n",
    "          print(\"Memory allocated in GPU: \", torch.cuda.memory_allocated(\"cuda:0\")/1024/1024/1024)\n",
    "        \"\"\"\n",
    "        \n",
    "      for batch_X, batch_y in tqdm(iter(val_dataloader)):\n",
    "\n",
    "        batch_X, batch_y = batch_X.type(torch.FloatTensor).to(device).permute(0, 3, 2, 1), batch_y.type(torch.FloatTensor).to(device)\n",
    "\n",
    "        net.eval() # Making sure that the model is not training and deactivate droptout\n",
    "        \n",
    "        with torch.no_grad(): # Disable all computations, works together with net.eval()\n",
    "          acc_aux, loss_aux, conf_m_aux = fwd_pass(batch_X, batch_y, train=False)\n",
    "\n",
    "        val_acc += acc_aux*(len(batch_X)/len(val_set)) # Calculating the average loss and acc trough batches\n",
    "        val_loss += loss_aux*(len(batch_X)/len(val_set))\n",
    "        val_conf_m += conf_m_aux\n",
    "\n",
    "\n",
    "      acc = (conf_m[0][0]+conf_m[1][1])/(conf_m[1][0]+conf_m[0][1]+conf_m[1][1]+conf_m[0][0]) # Better way to obtain acc tan using per batch acc\n",
    "      val_acc = (val_conf_m[0][0]+val_conf_m[1][1])/(val_conf_m[1][0]+val_conf_m[0][1]+val_conf_m[1][1]+val_conf_m[0][0])\n",
    "\n",
    "      prc = conf_m[1][1]/(conf_m[1][1]+conf_m[0][1])\n",
    "      val_prc = val_conf_m[1][1]/(val_conf_m[1][1]+val_conf_m[0][1])\n",
    "      rec = conf_m[1][1]/(conf_m[1][1]+conf_m[1][0])\n",
    "      val_rec = val_conf_m[1][1]/(val_conf_m[1][1]+val_conf_m[1][0])\n",
    "      f1 = 2*prc*rec/(prc+rec)\n",
    "      val_f1 = 2*val_prc*val_rec/(val_prc+val_rec)\n",
    "      \n",
    "      print(\"Val loss: \", val_loss.item(),\" Train loss: \", loss.item(), \"\\n\")\n",
    "      print(\"Val acc: \", val_acc,\" Train acc: \", acc, \"\\n\")\n",
    "      print(\"Val PRC:\", val_prc, \"Train PRC: \", prc) # TP/TP+FP\n",
    "      print(\"Val REC: \", val_rec,\"Train REC: \", rec) # TP/TP+FN\n",
    "      print(\"Val f1: \", val_f1,\" Train f1: \", f1, \"\\n\")\n",
    "      print(\"Val CONF: \\n\", val_conf_m,\"\\nTrain CONF: \\n\", conf_m, \"\\n\")\n",
    "\n",
    "      conf_m = f\"{conf_m[0][0]}+{conf_m[0][1]}+{conf_m[1][0]}+{conf_m[1][1]}\"\n",
    "      val_conf_m = f\"{val_conf_m[0][0]}+{val_conf_m[0][1]}+{val_conf_m[1][0]}+{val_conf_m[1][1]}\"\n",
    "    \n",
    "      f.write(f\"{MODEL_NAME},{round(time.time(),3)},{round(float(acc),3)},{round(float(loss),4)},{conf_m},{round(float(prc),4)},{round(float(rec),4)},\")\n",
    "      f.write(f\"{round(float(val_acc),3)},{round(float(val_loss),4)},{val_conf_m}, {round(float(val_prc),4)}, {round(float(val_rec),4)}\\n\")\n",
    "      f.write(\"\\n\\n\")\n",
    "\n",
    "      # Early stopping, if the difference between loss and validation loss \n",
    "      # is bigger than the threshold for 3 epochs in a row training is stopped\n",
    "      if loss.item()-val_loss.item()> threshold:\n",
    "        patience +=1\n",
    "      else:\n",
    "        patience = 0\n",
    "\n",
    "      print(\"Learning Rate: \", optimizer.param_groups[0][\"lr\"])\n",
    "      scheduler.step() # Changing the learning rate\n",
    "\n",
    "      if patience >= 4:\n",
    "        print(\"Stopping early: \")\n",
    "        break\n",
    "\n",
    "    torch.save(net, f\"C:\\\\Users\\\\Alejandro\\\\Desktop\\\\heterogeneous-data\\\\results\\\\WSI\\\\models\\\\{MODEL_NAME}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def test():\n",
    "  global test_set, test_dataloader, MODEL_NAME, MODE\n",
    "\n",
    "  with open(r\"C:\\Users\\Alejandro\\Desktop\\heterogeneous-data\\results\\WSI\\test.csv\", MODE) as f:\n",
    "    acc, loss = 0, 0\n",
    "    conf_m = np.array([[0,0],[0,0]])\n",
    "    for batch_X, batch_y in tqdm(iter(test_dataloader)):\n",
    "      batch_X, batch_y = batch_X.type(torch.FloatTensor).to(device).permute(0, 3, 2, 1), batch_y.type(torch.FloatTensor).to(device)\n",
    "\n",
    "      net.eval() # Making sure that the model is not training and deactivate droptout\n",
    "\n",
    "      with torch.no_grad(): # Disable all computations, works together with net.eval()\n",
    "          acc_aux, loss_aux, conf_m_aux = fwd_pass(batch_X, batch_y, train=False)\n",
    "\n",
    "      acc += acc_aux*(len(batch_X)/len(test_set)) # Calculating the average loss and acc trough batches\n",
    "      loss += loss_aux*(len(batch_X)/len(test_set))\n",
    "      conf_m += conf_m_aux\n",
    "\n",
    "    prc = conf_m[0][0]/(conf_m[0][0]+conf_m[0][1])\n",
    "    rec = conf_m[0][0]/(conf_m[0][0]+conf_m[0][1])\n",
    "    f1 = 2*prc*rec/(prc+rec)\n",
    "\n",
    "    print(\"Test loss: \", loss.item(), \"\\n\")\n",
    "    print(\"Test acc: \", acc, \"\\n\")\n",
    "    print(\"Test PRC: \", prc, \"\\n\") # TP/TP+FP\n",
    "    print(\"Test REC: \", rec, \"\\n\") # TP/TP+FN\n",
    "    print(\"f1: \", f1, \"\\n\")\n",
    "    print(\"\\nCONF: \\n\", conf_m, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training split: 2\n",
      "Read lmdb\n",
      "Loading training split: 3\n",
      "Read lmdb\n",
      "Loading training split: 4\n",
      "Read lmdb\n",
      "Loading training split: 5\n",
      "Read lmdb\n",
      "Loading training split: 6\n",
      "Read lmdb\n",
      "Loading training split: 7\n",
      "Read lmdb\n",
      "Loading training split: 8\n",
      "Read lmdb\n",
      "Loading training split: 9\n",
      "Read lmdb\n",
      "Patches for training: 118075\n",
      "\n",
      "Loading validation split: 0\n",
      "Read lmdb\n",
      "Patches for validation: 16928\n",
      "\n",
      "Loading test split: 1\n",
      "Read lmdb\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/Alejandro/Desktop/heterogeneous-data/data/patches/data_set_x20_100%_split1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alejandro\\Desktop\\heterogeneous-data\\code\\WSI\\wsi_train.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000008?line=66'>67</a>\u001b[0m     SPLIT_NAME \u001b[39m=\u001b[39m DATA_SET_NAME \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mSPLIT\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000008?line=67'>68</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLoading test split: \u001b[39m\u001b[39m{\u001b[39;00mSPLIT\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000008?line=69'>70</a>\u001b[0m X_, y_, _ , _ \u001b[39m=\u001b[39m data_reader\u001b[39m.\u001b[39;49mread_lmdb(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC:/Users/Alejandro/Desktop/heterogeneous-data/data/patches/\u001b[39;49m\u001b[39m{\u001b[39;49;00mSPLIT_NAME\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000008?line=71'>72</a>\u001b[0m test_set\u001b[39m.\u001b[39minputs\u001b[39m.\u001b[39mextend(X_)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000008?line=72'>73</a>\u001b[0m test_set\u001b[39m.\u001b[39mlabels\u001b[39m.\u001b[39mextend(y_)\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\Desktop\\heterogeneous-data\\code\\WSI\\data_reader.py:169\u001b[0m, in \u001b[0;36mread_lmdb\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/data_reader.py?line=165'>166</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_lmdb\u001b[39m(filename):\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/data_reader.py?line=166'>167</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mRead lmdb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/data_reader.py?line=168'>169</a>\u001b[0m     lmdb_env \u001b[39m=\u001b[39m lmdb\u001b[39m.\u001b[39;49mopen(filename)\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/data_reader.py?line=169'>170</a>\u001b[0m     \u001b[39m#lmdb_txn = lmdb_env.begin()\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/data_reader.py?line=171'>172</a>\u001b[0m     X, y, ids_X, ids_y \u001b[39m=\u001b[39m [], [], [], []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/Alejandro/Desktop/heterogeneous-data/data/patches/data_set_x20_100%_split1'"
     ]
    }
   ],
   "source": [
    "# Choosing only the images from the according splits (10CV)\n",
    "\n",
    "SPLITS = 1 # Number of iterations > n_splits\n",
    "n_splits = 10 # Number of splits to use\n",
    "\n",
    "for SPLIT in range(SPLITS):\n",
    "    MODEL_NAME = EXP_NAME + f\"{SPLIT}\"\n",
    "\n",
    "    TRAIN_SPLITS = list(range(n_splits))\n",
    "    # We take out the SPLIT and SPLIT+1 sets for val and testing\n",
    "    if SPLIT == n_splits: # For the final split for validation we take the firs one for test\n",
    "        TRAIN_SPLITS.remove(0) \n",
    "    else:\n",
    "        TRAIN_SPLITS.remove(SPLIT+1)\n",
    "    TRAIN_SPLITS.remove(SPLIT)\n",
    "\n",
    "    train_set = dataset.PatchDataset([], [], [])\n",
    "    val_set = dataset.PatchDataset([], [], [])\n",
    "    test_set = dataset.PatchDataset([], [], [])\n",
    "\n",
    "    # Loading training splits:\n",
    "    for i in TRAIN_SPLITS:\n",
    "        print(f\"Loading training split: {i}\")\n",
    "        SPLIT_NAME = DATA_SET_NAME + f\"{i}\"\n",
    "        \n",
    "        X_, y_, _ , _ = data_reader.read_lmdb(f\"C:/Users/Alejandro/Desktop/heterogeneous-data/data/WSI/patches/{SPLIT_NAME}\")\n",
    "\n",
    "        train_set.inputs.extend(X_)\n",
    "        train_set.labels.extend(y_)\n",
    "\n",
    "    # Random oversampler\n",
    "\n",
    "    y =  [i[0] for i in train_set.labels]\n",
    "    positive = sum(y)\n",
    "    class_sample_count = np.array([len(y)-positive ,positive])\n",
    "    weight = 1. / class_sample_count\n",
    "    samples_weight = np.array([weight[t] for t in y])\n",
    "    samples_weight = torch.from_numpy(samples_weight) # Probability for a sample to be sampled\n",
    "    #samples_weight = torch.tensor([1/len(samples_weight)]*len(samples_weight))\n",
    "    sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))#, replacement=False)\n",
    "    # Will take len(samples_weight) number of samples, this can be changed\n",
    "    \n",
    "    # Creating DataLoader\n",
    "    train_dataloader = DataLoader(train_set, batch_size=BATCH_SIZE, sampler=sampler)\n",
    "    \n",
    "    print(f\"Patches for training: {len(train_set)}\\n\")\n",
    "    \n",
    "    # Loading validation splits:\n",
    "    SPLIT_NAME = DATA_SET_NAME + f\"{SPLIT}\"\n",
    "\n",
    "    print(f\"Loading validation split: {SPLIT}\")\n",
    "\n",
    "    X_, y_, _ , _ = data_reader.read_lmdb(f\"C:/Users/Alejandro/Desktop/heterogeneous-data/data/WSI/patches/{SPLIT_NAME}\")\n",
    "\n",
    "    val_set.inputs.extend(X_)\n",
    "    val_set.labels.extend(y_)\n",
    "\n",
    "    val_dataloader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    print(f\"Patches for validation: {len(val_set)}\\n\")\n",
    "\n",
    "    # Loading validation splits:\n",
    "    if SPLIT == n_splits:\n",
    "        SPLIT_NAME = DATA_SET_NAME + f\"{0}\"\n",
    "        print(f\"Loading test split: {0}\")\n",
    "    else:\n",
    "        SPLIT_NAME = DATA_SET_NAME + f\"{SPLIT+1}\"\n",
    "        print(f\"Loading test split: {SPLIT+1}\")\n",
    "\n",
    "    X_, y_, _ , _ = data_reader.read_lmdb(f\"C:/Users/Alejandro/Desktop/heterogeneous-data/data/patches/{SPLIT_NAME}\")\n",
    "\n",
    "    test_set.inputs.extend(X_)\n",
    "    test_set.labels.extend(y_)\n",
    "\n",
    "    test_dataloader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    print(f\"Patches for test: {len(test_set)}\\n\")\n",
    "\n",
    "    init()\n",
    "\n",
    "    train()\n",
    "\n",
    "    del train_set, val_set, test_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_curve(NAME):\n",
    "  fig, axs = plt.subplots(2, figsize = (7,6))\n",
    "\n",
    "  acc_df = pd.read_csv(f\"C:\\\\Users\\\\Alejandro\\\\Desktop\\\\heterogeneous-data\\\\results\\\\WSI\\\\log\\\\model_{NAME}.log\")\n",
    "  acc_df.columns = [\"MODEL_NAME\", \"TIME\", \"ACC\", \"LOSS\", \"CONF_M\", \"PRC\", \"REC\",\n",
    "                     \"VAL_ACC\", \"VAL_LOSS\", \"VAL_CONF_M\", \"VAL_PRC\", \"VAL_REC\"]\n",
    "\n",
    "  fig, axs = plt.subplots(2, figsize=(5,7))\n",
    "\n",
    "  axs[0].legend(\"MODEL_NAME\", loc=2)\n",
    "\n",
    "  acc_df.plot(y=\"ACC\", ax=axs[0])\n",
    "  acc_df.plot(y=\"VAL_ACC\", ax=axs[0])\n",
    "\n",
    "  acc_df.plot(y=\"LOSS\", ax=axs[1])\n",
    "  acc_df.plot(y=\"VAL_LOSS\",ax=axs[1])\n",
    "\n",
    "  fig.show()\n",
    "  fig.savefig(f\"C:\\\\Users\\\\Alejandro\\\\Desktop\\\\heterogeneous-data\\\\results\\\\WSI\\\\lc\\\\l_curve_{NAME}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25ep_earlystp_ft0\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Alejandro\\Desktop\\heterogeneous-data\\code\\WSI\\wsi_train.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000010?line=1'>2</a>\u001b[0m NAME \u001b[39m=\u001b[39m EXP_NAME \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mSPLIT\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000010?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(NAME)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000010?line=3'>4</a>\u001b[0m learning_curve(NAME)\n",
      "\u001b[1;32mc:\\Users\\Alejandro\\Desktop\\heterogeneous-data\\code\\WSI\\wsi_train.ipynb Cell 10'\u001b[0m in \u001b[0;36mlearning_curve\u001b[1;34m(NAME)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000009?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlearning_curve\u001b[39m(NAME):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000009?line=1'>2</a>\u001b[0m   fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m2\u001b[39m, figsize \u001b[39m=\u001b[39m (\u001b[39m7\u001b[39m,\u001b[39m6\u001b[39m))\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000009?line=3'>4</a>\u001b[0m   acc_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC:\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mUsers\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mAlejandro\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mDesktop\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mheterogeneous-data\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mresults\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mWSI\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mlog\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mmodel_\u001b[39;49m\u001b[39m{\u001b[39;49;00mNAME\u001b[39m}\u001b[39;49;00m\u001b[39m.log\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000009?line=4'>5</a>\u001b[0m   acc_df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mMODEL_NAME\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mTIME\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mACC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mLOSS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mCONF_M\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPRC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mREC\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000009?line=5'>6</a>\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mVAL_ACC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mVAL_LOSS\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mVAL_CONF_M\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mVAL_PRC\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mVAL_REC\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Alejandro/Desktop/heterogeneous-data/code/WSI/wsi_train.ipynb#ch0000009?line=7'>8</a>\u001b[0m   fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m5\u001b[39m,\u001b[39m7\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=664'>665</a>\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=665'>666</a>\u001b[0m     dialect,\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=666'>667</a>\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=675'>676</a>\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=676'>677</a>\u001b[0m )\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=677'>678</a>\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=679'>680</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=571'>572</a>\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=573'>574</a>\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=574'>575</a>\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=576'>577</a>\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=577'>578</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=929'>930</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=931'>932</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=932'>933</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1235\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=1231'>1232</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m   <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=1233'>1234</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=1234'>1235</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions)\n\u001b[0;32m   <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=1235'>1236</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m   <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/readers.py?line=1236'>1237</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=71'>72</a>\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m     <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=73'>74</a>\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m---> <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=74'>75</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39mTextReader(src, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=76'>77</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[0;32m     <a href='file:///c%3A/Users/Alejandro/anaconda3/envs/openslide/lib/site-packages/pandas/io/parsers/c_parser_wrapper.py?line=78'>79</a>\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alejandro\\anaconda3\\envs\\openslide\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:551\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for SPLIT in range(1):\n",
    "    NAME = EXP_NAME + f\"{SPLIT}\"\n",
    "    print(NAME)\n",
    "    learning_curve(NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "de74446a7cd3a56c425ecbffb2a7ad915342ddab3c48353acb4566475bd7705f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('openslide')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
