{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "sample_sheet = pd.read_csv('D:/data/RNASeq/GDC/sample_sheet.tsv', sep='\\t')\n",
    "clinical = pd.read_csv('D:/data/RNASeq/GDC/clinical.tsv', sep='\\t')\n",
    "\n",
    "csv_name = \"gdcdataset_test\"\n",
    "csv_path = \"D:/data/RNASeq/dataset/\"\n",
    "\n",
    "paths = glob.glob('D:\\\\data\\\\RNASeq\\\\GDC\\\\gdc_download_20220707_111311.305944\\\\*')\n",
    "\n",
    "#iia = ['Stage I','Stage IA', 'Stage IB', 'Stage IIA']\n",
    "\n",
    "for SPLIT in range(10):\n",
    "    labels = []\n",
    "    runs = []\n",
    "    paths_array = []\n",
    "    sample_ids = []\n",
    "    case_ids = []\n",
    "\n",
    "    case_id = open(f\"C:\\\\Users\\\\Alejandro\\\\Desktop\\\\heterogeneous-data\\\\splits\\\\testsplit{SPLIT}.txt\", \"r\").read().split()\n",
    "    split_file_ids = list(sample_sheet[sample_sheet[\"Case ID\"].isin(case_id)][\"File ID\"])\n",
    "    for path in paths:\n",
    "        file_id = os.path.split(path)[-1]\n",
    "        if file_id in split_file_ids:\n",
    "            if not os.path.exists(path) or not os.path.isdir(path) or len(os.listdir(path)) == 0:\n",
    "                print(\"Path does not exist or empty \", path)\n",
    "                pass\n",
    "            else:\n",
    "                for file in glob.glob(path + r\"\\*\"+\".tsv\"):\n",
    "                    case_id = sample_sheet[sample_sheet[\"File ID\"] == file_id][\"Case ID\"].iloc[0]\n",
    "                    file_name = os.path.split(file)[-1]\n",
    "                    paths_array.append(path)\n",
    "                    runs.append(file_name)\n",
    "                    labels.append(sample_sheet[sample_sheet[\"File ID\"] == file_id][\"Sample Type\"].iloc[0])\n",
    "                    sample_ids.append(sample_sheet[sample_sheet[\"File ID\"] == file_id][\"Sample ID\"].iloc[0])\n",
    "                    case_ids.append(case_id)\n",
    "\n",
    "                    \"\"\"\n",
    "                    stage = clinical[clinical[\"case_submitter_id\"] == case_id][\"ajcc_pathologic_stage\"].iloc[0]\n",
    "                    if stage in iia:\n",
    "                        labels.append(\"iia\")\n",
    "                    else:\n",
    "                        labels.append(\"iib\")\n",
    "                    \"\"\"\n",
    "\n",
    "    # create dataset for knowseq\n",
    "    mergedCounts = pd.DataFrame()\n",
    "    mergedCounts['Path'] = paths_array\n",
    "    mergedCounts['Run'] = runs\n",
    "    mergedCounts['Class'] = labels\n",
    "    mergedCounts['Sample ID'] = sample_ids\n",
    "    mergedCounts['Case ID'] = case_ids\n",
    "\n",
    "    mergedCounts.to_csv(csv_path+\"labels/\"+csv_name+ str(SPLIT) +'.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(countsMatrix_train):\n",
    "    for row in countsMatrix_train.iterrows():\n",
    "        not_expressed = all(v == 0 for v in list(row[1]))\n",
    "        if \"PAR_Y\" in row[0] and not_expressed:\n",
    "            countsMatrix_train.drop(index=row[0], inplace=True)\n",
    "\n",
    "    countsMatrix_train.index = [index.split(\".\")[0] for index in countsMatrix_train.index]\n",
    "    #dataGtex_split.index = [index.split(\".\")[0] for index in dataGtex_split.index]\n",
    "\n",
    "    countsMatrix_train = pd.concat([countsMatrix_train], axis=1)#, dataGtex_split], axis=1) # Concatenating all GTEx and GDC data for the split\n",
    "\n",
    "\n",
    "    countsMatrix_train.fillna(0, inplace=True)\n",
    "\n",
    "    return countsMatrix_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split:  0\n",
      "Split:  1\n",
      "Split:  2\n",
      "Split:  3\n",
      "Split:  4\n",
      "Split:  5\n",
      "Split:  6\n",
      "Split:  7\n",
      "Split:  8\n",
      "Split:  9\n"
     ]
    }
   ],
   "source": [
    "# Knowseq does not work with STAR count files from GDC, therefore a full matrix must be created \n",
    "# COLUMNS=> SAMPLE_ID ROW=> GEN_ID The labels can be taken using R from the given .csv file\n",
    "# lo que devuelve Knoqseq son dos columnas $countsMatrix (X) y $labels(y)\n",
    "\n",
    "n_splits = 10\n",
    "\n",
    "dataGtex = pd.read_csv(\"D:/data/RNASeq/GTEx/gene_reads_pancreas.gct\", sep=\"\\t\", header=2)\n",
    "\n",
    "dataGtex.index = dataGtex[\"Name\"]\n",
    "dataGtex.drop(columns=[\"id\",\"Description\", \"Name\"], inplace=True)\n",
    "\n",
    "for SPLIT in range(n_splits):\n",
    "    print(\"Split: \", SPLIT)\n",
    "    countsMatrix = []\n",
    "    gdcDataset=[]\n",
    "    \n",
    "    TRAIN_SPLITS = list(range(n_splits))\n",
    "    # We take out the SPLIT and SPLIT+1 sets for val and testing\n",
    "    if SPLIT == n_splits-1: # For the final split for validation we take the first one for test\n",
    "        TRAIN_SPLITS.remove(0) \n",
    "    else:\n",
    "        TRAIN_SPLITS.remove(SPLIT+1)\n",
    "    TRAIN_SPLITS.remove(SPLIT)\n",
    "\n",
    "    for TRAIN_SPLIT in TRAIN_SPLITS:\n",
    "        mergedCounts = pd.read_csv(csv_path+\"labels/\"+csv_name+str(TRAIN_SPLIT)+'.csv', sep=',')\n",
    "        gdcDataset.append(mergedCounts)\n",
    "\n",
    "        for sample_id, path, name, label in zip(mergedCounts['Sample ID'], mergedCounts['Path'], mergedCounts['Run'], mergedCounts['Class']):\n",
    "            counts = pd.read_csv(path+\"\\\\\"+name, sep='\\t', header=1)#[\"unstranded\"]\n",
    "            counts = counts.set_index(\"gene_id\")[\"unstranded\"]\n",
    "            counts.name = sample_id\n",
    "            countsMatrix.append(counts)\n",
    "\n",
    "    gdcDataset_train = pd.concat(gdcDataset) # All GDC labels\n",
    "    countsMatrix_train = pd.concat(countsMatrix, axis=1) # All GDC splits are concatenated\n",
    "\n",
    "    # TEST\n",
    "\n",
    "    gdcDataset_test = pd.read_csv(csv_path+\"labels/\"+csv_name+str(SPLIT)+'.csv', sep=',')\n",
    "    countsMatrix = []\n",
    "\n",
    "    for sample_id, path, name, label in zip(gdcDataset_test['Sample ID'], gdcDataset_test['Path'], gdcDataset_test['Run'], gdcDataset_test['Class']):\n",
    "            counts = pd.read_csv(path+\"\\\\\"+name, sep='\\t', header=1)#[\"unstranded\"]\n",
    "            counts = counts.set_index(\"gene_id\")[\"unstranded\"]\n",
    "            counts.name = sample_id\n",
    "            countsMatrix.append(counts)\n",
    "\n",
    "    countsMatrix_test = pd.concat(countsMatrix, axis=1) # All GDC splits are concatenated\n",
    "\n",
    "    \"\"\"    \n",
    "    # Selecting all samples that have a Case ID in belonging to the corresponding split\n",
    "    case_id = open(f\"C:\\\\Users\\\\Alejandro\\\\Desktop\\\\heterogeneous-data\\\\splits\\\\trainsplit{SPLIT}.txt\", \"r\").read().split()\n",
    "    split_sample_ids = [sample_id for sample_id in dataGtex.columns if (\"-\".join(sample_id.split(\"-\")[:2]) in case_id)]\n",
    "    dataGtex_split = dataGtex[split_sample_ids]\n",
    "\n",
    "    gtexDataset = pd.DataFrame({\"Case ID\": [\"-\".join(sample_id.split(\"-\")[:2]) for sample_id in list(dataGtex_split.columns)],\n",
    "                                \"Sample ID\":list(dataGtex_split.columns), \n",
    "                                \"Class\":[\"Solid Tissue Normal\" for i in dataGtex_split.columns]})\n",
    "\n",
    "    #data.to_csv(csv_path + 'countsMatrixGTEx.csv', sep=',')\n",
    "\n",
    "    #Deleting double (sexual) genes that are not expressed\n",
    "    for row in dataGtex_split.iterrows():\n",
    "        not_expressed = all(v == 0 for v in list(row[1]))\n",
    "        if \"PAR_Y\" in row[0] and not_expressed:\n",
    "            dataGtex_split.drop(index=row[0], inplace=True)\n",
    "    \"\"\"\n",
    "\n",
    "    countsMatrix_train = clean_data(countsMatrix_train)\n",
    "    countsMatrix_test = clean_data(countsMatrix_test)\n",
    "\n",
    "\n",
    "    gdcDataset_train.to_csv(csv_path+'labels/gdcdataset_train'+str(SPLIT)+'.csv', sep =',')\n",
    "    gdcDataset_test.to_csv(csv_path+'labels/gdcdataset_test'+str(SPLIT)+'.csv', sep =',')\n",
    "\n",
    "    #gtexDataset.to_csv(csv_path+'labels/gtexdataset'+str(SPLIT)+'.csv', sep =',')\n",
    "    \n",
    "    countsMatrix_train.to_csv(csv_path+'countsMatrix/countsMatrixGDC_train_split'+str(SPLIT)+'.csv', sep=',')\n",
    "    countsMatrix_test.to_csv(csv_path+'countsMatrix/countsMatrixGDC_test_split'+str(SPLIT)+'.csv', sep=',')\n",
    "\n",
    "    #countsMatrix.to_csv(csv_path+'countsMatrix/countsMatrixGDC+GTEX_split'+str(SPLIT)+'.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TCIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "sample_sheet = pd.read_csv('D:/data/RNASeq/PDAC/sample_sheet.tsv', sep='\\t')\n",
    "clinical = pd.read_csv('D:/data/RNASeq/PDAC/clinical.tsv', sep='\\t')\n",
    "\n",
    "sample_sheet[\"Sample ID\"] = sample_sheet[\"Sample ID\"].str.split(\",\")\n",
    "sample_sheet[\"Case ID\"] = sample_sheet[\"Case ID\"].str.split(\",\")\n",
    "sample_sheet[\"Sample Type\"] = sample_sheet[\"Sample Type\"].str.split(\",\")\n",
    "sample_sheet = sample_sheet.explode(\"Sample ID\").explode(\"Case ID\").explode(\"Sample Type\")\n",
    "\n",
    "csv_name = \"pdac_dataset_test\"\n",
    "csv_path = \"D:/data/RNASeq/dataset/\"\n",
    "\n",
    "paths = glob.glob('D:\\\\data\\\\RNASeq\\\\PDAC\\\\gdc_download_20220913_143316.680608\\\\*')\n",
    "\n",
    "for SPLIT in range(10):\n",
    "    labels = []\n",
    "    runs = []\n",
    "    paths_array = []\n",
    "    sample_ids = []\n",
    "    case_ids = []\n",
    "\n",
    "    case_id = open(f\"C:\\\\Users\\\\Alejandro\\\\Desktop\\\\heterogeneous-data\\\\splits\\\\tcia_testsplit{SPLIT}.txt\", \"r\").read().split()\n",
    "    split_file_ids = list(sample_sheet[sample_sheet[\"Case ID\"].isin(case_id)][\"File ID\"])\n",
    "\n",
    "    for path in paths:\n",
    "        file_id = os.path.split(path)[-1]\n",
    "        if file_id in split_file_ids:\n",
    "            if not os.path.exists(path) or not os.path.isdir(path) or len(os.listdir(path)) == 0:\n",
    "                print(\"Path does not exist or empty \", path)\n",
    "                pass\n",
    "            else:\n",
    "                for file in glob.glob(path + r\"\\*\"+\".tsv\"):\n",
    "                    case_id = sample_sheet[sample_sheet[\"File ID\"] == file_id][\"Case ID\"].iloc[0]\n",
    "                    file_name = os.path.split(file)[-1]\n",
    "                    paths_array.append(path)\n",
    "                    runs.append(file_name)\n",
    "                    labels.append(sample_sheet[sample_sheet[\"File ID\"] == file_id][\"Sample Type\"].iloc[0])\n",
    "                    sample_ids.append(sample_sheet[sample_sheet[\"File ID\"] == file_id][\"Sample ID\"].iloc[0])\n",
    "                    case_ids.append(case_id)\n",
    "\n",
    "    # create dataset for knowseq\n",
    "    mergedCounts = pd.DataFrame()\n",
    "    mergedCounts['Path'] = paths_array\n",
    "    mergedCounts['Run'] = runs\n",
    "    mergedCounts['Class'] = labels\n",
    "    mergedCounts['Sample ID'] = sample_ids\n",
    "    mergedCounts['Case ID'] = case_ids\n",
    "\n",
    "    mergedCounts.to_csv(csv_path+\"labels/\"+csv_name+ str(SPLIT) +'.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split:  0\n",
      "Split:  1\n",
      "Split:  2\n",
      "Split:  3\n",
      "Split:  4\n",
      "Split:  5\n",
      "Split:  6\n",
      "Split:  7\n",
      "Split:  8\n",
      "Split:  9\n"
     ]
    }
   ],
   "source": [
    "# Knowseq does not work with STAR count files from GDC, therefore a full matrix must be created \n",
    "# COLUMNS=> SAMPLE_ID ROW=> GEN_ID The labels can be taken using R from the given .csv file\n",
    "# lo que devuelve Knoqseq son dos columnas $countsMatrix (X) y $labels(y)\n",
    "\n",
    "n_splits = 10\n",
    "\n",
    "for SPLIT in range(n_splits):\n",
    "    print(\"Split: \", SPLIT)\n",
    "    countsMatrix = []\n",
    "    gdcDataset=[]\n",
    "    \n",
    "    TRAIN_SPLITS = list(range(n_splits))\n",
    "    # We take out the SPLIT and SPLIT+1 sets for val and testing\n",
    "    if SPLIT == n_splits-1: # For the final split for validation we take the first one for test\n",
    "        TRAIN_SPLITS.remove(0) \n",
    "    else:\n",
    "        TRAIN_SPLITS.remove(SPLIT+1)\n",
    "    TRAIN_SPLITS.remove(SPLIT)\n",
    "\n",
    "    for TRAIN_SPLIT in TRAIN_SPLITS:\n",
    "        mergedCounts = pd.read_csv(csv_path+\"labels/\"+csv_name+str(TRAIN_SPLIT)+'.csv', sep=',')\n",
    "        gdcDataset.append(mergedCounts)\n",
    "\n",
    "        for sample_id, path, name, label in zip(mergedCounts['Sample ID'], mergedCounts['Path'], mergedCounts['Run'], mergedCounts['Class']):\n",
    "            counts = pd.read_csv(path+\"\\\\\"+name, sep='\\t', header=1)#[\"unstranded\"]\n",
    "            counts = counts.set_index(\"gene_id\")[\"unstranded\"]\n",
    "            counts.name = sample_id\n",
    "            countsMatrix.append(counts)\n",
    "\n",
    "    gdcDataset_train = pd.concat(gdcDataset) # All GDC labels\n",
    "    countsMatrix_train = pd.concat(countsMatrix, axis=1) # All GDC splits are concatenated\n",
    "\n",
    "    # TEST\n",
    "\n",
    "    gdcDataset_test = pd.read_csv(csv_path+\"labels/\"+csv_name+str(SPLIT)+'.csv', sep=',')\n",
    "    countsMatrix = []\n",
    "\n",
    "    for sample_id, path, name, label in zip(gdcDataset_test['Sample ID'], gdcDataset_test['Path'], gdcDataset_test['Run'], gdcDataset_test['Class']):\n",
    "            counts = pd.read_csv(path+\"\\\\\"+name, sep='\\t', header=1)#[\"unstranded\"]\n",
    "            counts = counts.set_index(\"gene_id\")[\"unstranded\"]\n",
    "            counts.name = sample_id\n",
    "            countsMatrix.append(counts)\n",
    "\n",
    "    countsMatrix_test = pd.concat(countsMatrix, axis=1) # All GDC splits are concatenated\n",
    "\n",
    "    countsMatrix_train = clean_data(countsMatrix_train)\n",
    "    countsMatrix_test = clean_data(countsMatrix_test)\n",
    "\n",
    "    gdcDataset_train.to_csv(csv_path+'labels/TCIAdataset_train'+str(SPLIT)+'.csv', sep =',')\n",
    "    gdcDataset_test.to_csv(csv_path+'labels/TCIAdataset_test'+str(SPLIT)+'.csv', sep =',')\n",
    "\n",
    "    #gtexDataset.to_csv(csv_path+'labels/gtexdataset'+str(SPLIT)+'.csv', sep =',')\n",
    "    \n",
    "    countsMatrix_train.to_csv(csv_path+'countsMatrix/countsMatrixTCIA_train_split'+str(SPLIT)+'.csv', sep=',')\n",
    "    countsMatrix_test.to_csv(csv_path+'countsMatrix/countsMatrixTCIA_test_split'+str(SPLIT)+'.csv', sep=',')\n",
    "\n",
    "    #countsMatrix.to_csv(csv_path+'countsMatrix/countsMatrixGDC+GTEX_split'+str(SPLIT)+'.csv', sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split:  0\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Split:  1\n",
      "0\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Split:  2\n",
      "0\n",
      "1\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Split:  3\n",
      "0\n",
      "1\n",
      "2\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Split:  4\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Split:  5\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "7\n",
      "8\n",
      "9\n",
      "Split:  6\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "8\n",
      "9\n",
      "Split:  7\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "9\n",
      "Split:  8\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "Split:  9\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "\n",
    "for SPLIT in range(n_splits):\n",
    "    print(\"Split: \", SPLIT)\n",
    "    \n",
    "    TRAIN_SPLITS = list(range(n_splits))\n",
    "    # We take out the SPLIT and SPLIT+1 sets for val and testing\n",
    "    if SPLIT == n_splits-1: # For the final split for validation we take the first one for test\n",
    "        TRAIN_SPLITS.remove(0) \n",
    "    else:\n",
    "        TRAIN_SPLITS.remove(SPLIT+1)\n",
    "    TRAIN_SPLITS.remove(SPLIT)\n",
    "\n",
    "    for TRAIN_SPLIT in TRAIN_SPLITS:\n",
    "        print(TRAIN_SPLIT)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('openslide')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de74446a7cd3a56c425ecbffb2a7ad915342ddab3c48353acb4566475bd7705f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
